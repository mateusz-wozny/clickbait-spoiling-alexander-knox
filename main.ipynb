{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify spoiler-type using BLOOM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_using_bloom import load_data, classify_spoiler_type, calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = classify_spoiler_type(examples_per_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(test_df, predicted_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify spoiler-type using spoiler generated by BLOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "\n",
    "from bloom_generate_spoilers import generate_spoilers\n",
    "from dataset_class import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset.from_jsonl(\"data/validation.jsonl\")\n",
    "val_df = pd.DataFrame()\n",
    "val_df[\"text\"] =\"Question: \\n\" + val_dataset.df[\"postText\"] + \"\\nContext: \\n\"+ val_dataset.df[\"targetParagraphs\"].apply(lambda x: \". \".join(x)[:2500])+ \"\\nAnswer: \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoilers = generate_spoilers(val_df, examples_per_class=2, number_of_generated_spoilers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoilers_df = pd.DataFrame(spoilers, columns=[\"spoiler\"])\n",
    "spoilers_df.replace(\" \", np.nan, inplace=True)\n",
    "spoilers_df.to_csv(\"data/spoilers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from dataset_class import Dataset as MyDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "datapath = \"data/train.jsonl\"\n",
    "dataset = MyDataset.from_jsonl(datapath)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = (\n",
    " \"Clickbait: \\n \" + dataset.df[\"postText\"] + \" Spoiler: \\n\" + dataset.df[\"spoiler\"]\n",
    ")\n",
    "df[\"tags\"] = dataset.df[\"tags\"]\n",
    "val_dataset = MyDataset.from_jsonl(\"data/validation.jsonl\")\n",
    "spoilers_df=pd.read_csv(\"data/spoilers.csv\")\n",
    "spoilers_df=spoilers_df.fillna(\" \")\n",
    "val= pd.DataFrame()\n",
    "val[\"text\"]=\"Clickbait: \\n \" +val_dataset.df[\"postText\"] + \" Spoiler: \\n\" + spoilers_df['spoiler']\n",
    "val[\"tags\"]=val_dataset.df[\"tags\"]\n",
    "test = val.iloc[300:]\n",
    "df = pd.concat([df.iloc[:2500], val.iloc[:300]])\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, stratify=df[\"tags\"])\n",
    "labels = {\"phrase\": 0, \"passage\": 1, \"multi\": 2}\n",
    "df_train.rename(columns={\"tags\": \"label\"}, inplace=True)\n",
    "df_train[\"label\"] = df_train[\"label\"].apply(lambda x: labels[x])\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "df_val.rename(columns={\"tags\": \"label\"}, inplace=True)\n",
    "df_val[\"label\"] = df_val[\"label\"].apply(lambda x: labels[x])\n",
    "val_dataset = Dataset.from_pandas(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_training import train, preprocess_function\n",
    "\n",
    "ckpts = [\"microsoft/deberta-base\", \"distilbert-base-uncased\", \"albert-base-v2\", \"roberta-base\"]\n",
    "model_checkpoint = f\"{ckpts[3]}-finetuned\"\n",
    "trainer = train(ckpts[3], train_dataset, val_dataset, batch_size=8, lr = 2e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "test[\"label\"] = test[\"tags\"].apply(lambda x: labels[x])\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "predictions = pred.predictions.argmax(1)\n",
    "acc = balanced_accuracy_score(pred.label_ids, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(pred.label_ids, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune model using clickbait post and linked web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from dataset_class import Dataset as MyDataset\n",
    "import pandas as pd\n",
    "\n",
    "labels = {\"phrase\": 0, \"passage\": 1, \"multi\": 2}\n",
    "\n",
    "\n",
    "train_dataset = MyDataset.from_jsonl(\"data/train.jsonl\")\n",
    "df[\"text\"] = (\n",
    " \"Clickbait\\n\" + dataset.df[\"postText\"] +  \"\\nArticle\\n\" + dataset.df[\"targetParagraphs\"].apply(lambda x: \". \".join(x)[:2000])  \n",
    ")\n",
    "df[\"tags\"] = dataset.df[\"tags\"]\n",
    "\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, stratify=df[\"tags\"])\n",
    "labels = {\"phrase\": 0, \"passage\": 1, \"multi\": 2}\n",
    "\n",
    "df_train.rename(columns={\"tags\": \"label\"}, inplace=True)\n",
    "df_train[\"label\"] = df_train[\"label\"].apply(lambda x: labels[x])\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "df_val.rename(columns={\"tags\": \"label\"}, inplace=True)\n",
    "df_val[\"label\"] = df_val[\"label\"].apply(lambda x: labels[x])\n",
    "val_dataset = Dataset.from_pandas(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_training import train, preprocess_function\n",
    "\n",
    "ckpts = [\"microsoft/deberta-base\", \"distilbert-base-uncased\", \"albert-base-v2\", \"roberta-base\"]\n",
    "model_checkpoint = f\"{ckpts[3]}-finetuned\"\n",
    "trainer = train(model_checkpoint, train_dataset, val_dataset, batch_size=6, lr = 2e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "datapath = \"data/validation.jsonl\"\n",
    "test = MyDataset.from_jsonl(datapath)\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"text\"] = \"Clickbait: \\n \" +test.df[\"postText\"] +  \"\\nArticle\\n\" + test.df[\"targetParagraphs\"].apply(lambda x: \". \".join(x)[:2000])  \n",
    "test_df[\"label\"] = test.df[\"tags\"].apply(lambda x: labels[x])\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "test_dataset = test_dataset.map(lambda x: preprocess_function(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "predictions = pred.predictions.argmax(1)\n",
    "acc = balanced_accuracy_score(pred.label_ids, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(pred.label_ids, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
